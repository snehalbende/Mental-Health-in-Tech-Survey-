---
output:
  html_document: default
  pdf_document: default
---
#Final Project - Predictive Analytics
#Team Members - Indrayani Deshmukh, Snehal Bende, Sindhu Ramaswamy
#Mental Health Survey data OSMI


# 1. Project Description

Mental health costs in the US are continuously rising since 2010 and are expected to double by the year 2030. Mental health thus, is of extreem importance.This project is a kaggle dataset titled " Mental health in Tech Survey". This dataset is a survey conducted in 2014  by the Open Sourcing Mental illness (OSMI) to monitor mental health disorders in the Tech industry. OSMI is a non-profit organization and their aim is to help people in the tech industry with mental health disorders so they have a good work life balance. 

# 2.Project Goal

Our idea behind choosing this dataset is identifying the people who need to seek mental health care in the tech industry and, what are the factorsthat are contributing to the increase in mental health problems in the industry? In today’s fast paced world there are many reasons for mental health issues and they often result in  poor work-life balance. Thus, actions are needed to be taken by companies by providing assistance with mental health care and having a good environment and work life for better performance of their employees. We are also curious to see if the factors like gender, age or employees with family history are more susceptible to having mental health disorder? Our goal for the project is to find the answers to these interesting questions. 

# 3.Steps followed for the project

The project code is done in R and the final report is compiled with R markdown. The detailed steps, data analysis and the reuslts are in the following sections of the report. 

###  a) Data Exploration and summary Statistics
###  b) Data Munging and Preparation
###  c) Feature Engineering
###  d) Modeling
###  e) Optimization
###  f) Results and Conclusion

# Loading libraries
The following libraries were loaded and packages were installed which were required to perform tasks for the project.

```{r,message=FALSE}

#Installing the packages and loading them.
install_load <- function (packages)  {   
  
  for(package in packages){
    
    # If package is installed
    if(package %in% rownames(installed.packages()))
      do.call('library', list(package))
    
    # If package is not installed
    else {
      install.packages(package, dependencies = TRUE)
      do.call("library", list(package))
    }
  } 
}

# loading the required librarires
libs <- c("ggplot2", "maps","magrittr","plotly", "plyr", "dplyr", "rworldmap","stringr","lubridate", "plotly", "reshape2","magrittr","ggthemes","tidyr", "DT", "lubridate","RColorBrewer","tidyverse","gridExtra")
install_load(libs)

# Loading specific methods from libraries
libs.methods <- c("C50", "lattice", "caret", "nnet", "e1071","Matrix", "foreach","glmnet","C50","randomForest","ipred","rpart")
install_load(libs.methods)
```

The data file survey.csv was read to perform further tasks.
```{r,message = FALSE}
survey_data <- read.csv(file.choose())
```

# Structure and summary of the survey data
```{r}
str(survey_data)
summary(survey_data)# summary of the survey data
dim(survey_data) #dimension of the survey data
```
As we see there are total of 1259 observations and 27 columns related to mental health questions and the demographic information in the dataset. As we are interested to see the results in the tech industry we might not need to use all the variables.From the results we see that there are 1095 missing values and the variables age, state and self_employed have NA values. Gender variable has duplicate values. 

library(dplyr)

# Selection of Target and predictor Variables

Based on the project goal, we selected 'treatment' as the target variable. Treatment variable tells us if the interviewed employee have sought mental health treatment or not. It is categorical in nature. 'Tech company'(binary variable) another variable which is considered to be a predictor variable tells if the company is a tech or a non tech company. Gender (categorical variable) - predictor variable tells us if the interviewed employee is male or a female. Age(continuous variable) - predictor variable tells the age of the employee. Family history (binary variable) - predicotr variable, tells if a person has a family history of mental health disorder. no_employees (categorical varible) - predictor variable, tells about the totol number of employees in the company.The new data comprising the targeta nd predicotr variables includes 1259 rows and 6 columns.

```{r}
survey <- survey_data %>% select(treatment, Age, Gender, family_history, no_employees, tech_company) 
# checking structure of data including selected variables
str(survey)
```

# Full Logistic Regression Model

We built the logistic regression model considereing 80% of the data to review our selection for target and predictor variables. Though we are aware, some variables in the logistic regression model below are not related to our project goal, we wanted to see the p values and re think on our variable selection approach.
```{r}
#Logistic Regression model considereing 80% of the variables 
lm1 <- glm(treatment ~ Age + Gender + Country + state + self_employed + family_history + work_interfere + no_employees + remote_work + tech_company + benefits + care_options + leave + mental_vs_physical+coworkers +seek_help , data = survey_data, family = "binomial" )
summary(lm1)
```
We got an AIC score of 578.94 and significant variables with lowest p values to be family_history, work_interefere, no_employees, care_options and seek_help. We conclude that care_options , work_interefere and seek_help variables are not closely tied to our project goal , hence we move forward with our selection for predictor variables.

# Treatment, Family history and tech company

# Inspecting Variables in detail
```{r}
#Studying each variable in detail 
table(survey$treatment)
table(survey$family_history) 
table(survey$tech_company)
```
Treatment, family history and tech company are all binary variables with no missing data or outliers. Out of the total interviewed people in the survey, 637 have sought mental health treatment and 622 have not. Thus we see that more than 50% of the people in the survey data have sought mental health treatment.Family history is also a binary variable with no missing data. The output shows more than 60% of the people in the survey do not have a family history of having a mental disorder.The survey comprised of 1031 tech companies and 228 non tech companies.

# Number of Employees
Number of employees is not an ordered variable.We order this variable which will help us visualize if there is a trend in the company size and the employees seeking mental health treatment.We are interested to see if the size of the company has a direct relation to seeking mental health care. As there is a general notion that employees working in a startup have more responsibilites and work pressure than the ones working in a large company. 
```{r}
#no_employees is not an ordered variable.
#Ordering the no_employees variable
summary(survey$no_employees)
employees_level_order <- factor(survey$no_employees, levels = c("1-5","6-25","26-100","100-500", "500-1000","More than 1000"))
```
There are 6 groups in the no_employees category.

```{r}
# Company distribution graph
survey %>% ggplot(aes(x=employees_level_order))+
  geom_bar(fill = "lightgreen") + ggtitle("Company Size: Ordered")
```
The above graph tells us that there is no specific trend with the size of the comapny and the employees seeking treatment. However, we can say that small companies and large companies with more than 1000 employees do have more people seeking mentak health treatment.Companies sized 6-25 and 26-100 have similar rate of seeking the treatment.

# GENDER
To further explore and inspect the selected variables, we are interested to see if gender has  somthing to do with seeking the treatment. Are female employees more in number to seek the treatment than male? 

Gender variable has outliers and includes values like 'Malr','m','F','Genderqueer' and so on. So we decide to categories the gender variable in three categories as "Male", "Female" and "Queer".We first list the three categories in the code and then categories the values in the list to their respective categories.

```{r,message=FALSE}
# Listing categories

Male <- c("Male ","Cis Man", "Malr", "Male", "male", "M", "m", "Male-ish", "maile", "Mal", "Male (CIS)", "Cis Male", "Make", "Male", "Man", "msle", "Mail", "cis male")
Female <- c("Female ","femail","Female (cis)","female","Female","F","Woman","f","Femake","woman","Female","cis-female/femme", "Cis Female", "Trans-female", "Female (trans)", "Trans woman")
Queer <-c ("ostensibly male, unsure what that really means","p","A little about you","queer","Neuter","something kinda male?","non-binary","Nah","All","Enby","fluid","Genderqueer","Androgyne","Agender","Guy (-ish) ^_^","male leaning androgynous", "queer/she/they")
```

```{r,message=FALSE}
#categorizing gender variable
survey$Gender <- sapply(
  as.vector(survey$Gender),
  function(x) if(x %in% Male) "Male" else x ) 

survey$Gender <- sapply(
  as.vector(survey$Gender),
  function(x) if(x %in% Female) "Female" else x ) 

survey$Gender <- sapply(
  as.vector(survey$Gender),
  function(x) if(x %in% Queer) "Queer" else x ) 
survey$Gender <- as.factor(survey$Gender)
```

Let's view the results and the number of employees in each of the categories
```{r}
# Records in each category
table(survey$Gender)
table(survey$Gender)/length(survey$Gender) #studying the relative frequency of the gender variable
```
We see that there is significantly a number of Male population in the survey. This is obvious as number of male employees in tech companies are more as compared to female employees. There is a low number in 'Queer' population.We also wanted to fetch the results for the relative frequency of the population of females, males and queer. We observe that male consi=titutes a large number in the survey.

```{r}

# Visualize the number of subjects in each gender type  

x=1
```

The above graph is a result of categorizing the gender variable and helps us to visualize the ratio of female, male and queer in the data. 

# AGE
Age variable has outliers as previously seen in the summary. It has negative values along with extreemly high values. We need to handle the outliers in the age variable and replace it with the median values to keep the data integrity. In the following code, we replaced the outliers with the median values.The summary of the transformed variable is shown in the output
```{r,message=FALSE}
# Age Variable --Outlier management: replacing with median value
survey$Age[which(survey$Age<0)]<- median(survey$Age)
survey$Age[which(survey$Age>100)]<- median(survey$Age)
Age_one <- survey$Age
Age_one
```
```{r}
# Summary Age
summary(survey$Age)
```
Plotting the histogram to see if the distribution of the transformed age variable.

```{r}
g2 <- ggplot(survey,aes(x=Age))+geom_histogram(aes(y=..density..), fill="pink")+geom_density(col="#3438BD",alpha = 0.5)+labs(x="Age",title="Transformed Age Distribution")
g2
```
The histogram shows that the outliers are taken care of and that the data is without anomalies.

After handing the outliers, we can categorize the age data so it will be great to understand the age group of people seeking mental health care. We categorize the age in four groups namely, 'Fresh' including the age group of - 0 to 16, 'Junior' in the age group of 17 to 34, 'Senior' in the age group of 35 to 60 and 'Super' in the age group of 61 to 70.
```{r}
# Age variable categorization
survey$Age<-cut(survey$Age, breaks = c(0, 16, 34, 60, 75), labels = c('Fresh', 'Junior', 'Senior', 'Super'))
table(survey$Age) 
```

The code below is for grouping the data in each age category.
```{r,message=FALSE}
# Group by Age Group and count each group
age_group <- survey %>%
  group_by(Age) %>%
  dplyr::summarize(count = n())
age_group
```
```{r}
g3 <- ggplot(age_group, aes(x = Age, y = count, fill = Age)) +  
  geom_bar(stat = "identity", alpha = 0.5) +
  xlab("Age Group") + 
  ylab("Number of People") + 
  ggtitle("Age Group in the Tech Survey")

g3
```
The above graph shows that the large number of employees in the survey data are from the age category Junior and Senior.It is relatable as people in the age group of 0 to 16 hardly work in the tech companies as they are still in the process of education and people above the age of 61 generally retire from the tech comapnies.

Let's look at the final data frame we have.
```{r}
summary(survey)
```
# Studying the relationships between target and predictor variables
We want to have a closer look at the variables we selected as predictors and see if they have a strong relationship with our target variable.The following graph shows the relation between tech_company variable and the treatment variable.

```{r}

# treatment ratio for tech companies
survey %>% ggplot(aes(x=tech_company, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Treatment Ratio in the Tech companies")
```
The above graph shows that there is a strong realtion between treatment and tech comapny variable. This also shows that even in the non tech comapny, the ratio of seeking mental health care is similar to that of the tech comapny.

As our focus is on tech comapnies, we will filter the data to include results for only the tech companies.
```{r}
# Focusing only on the data related to the Tech company 
Tech <- survey %>% select(treatment, Age, Gender, family_history, no_employees, tech_company) %>% filter(tech_company == "Yes")
summary(Tech)
```
The following graphs show the results of treatment in each of the age groups focused only on tech industry.This will give a clear picture of more susceptible age groups seeking mental health care in the tech industry.

```{r}
# Age Distribution graph
Age_1 <- survey %>% ggplot(aes(x=Age_one, fill = factor(treatment))) +
  geom_density(alpha = 0.5) + ggtitle("Distribution of Age")
Age_1

# Comparing treatment ratio in Age groups
Age_2 <- survey %>% ggplot(aes(x=Age, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Treatment Ratio per Age Groups")
Age_2

# Comparing treatment ratio in Age groups focusing on tech field
Age_3 <- Tech %>% ggplot(aes(x=Age, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Treatment Ratio per Age Groups based on tech field")
Age_3
```
We get that the junior and the senior are the two groups in the tech industry who often seek mental health care treatment.

In the process of studying the relationship between the target and the predictor variable, we do observe a strong relationship in the variables till now. Let's explore the realtionship between the gender variable and the treatment (target variable). We do that by plotting the below graphs.
```{r}
# Comparing treatment ratio in Gender groups
g1 <- survey %>% ggplot(aes(x=Gender, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Treatment Ratio")
g1
# Comparing treatment ratio in Gender groups focusing on tech industry
g2 <- Tech %>% ggplot(aes(x=Gender, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Treatment Ratio based on tech industry")

g2

```
the graphs show that female and Queer employees in the tech industry sought mental health care more as compare to male employees. This also tells us that the female and queer employees might be more stressed due to increased compition in the industry and the pressure if performance.Another reason can be that, female generally have other responsibilities than work which might casue them to be more pressurized. This gives an important insight that female employees need more supervision in the tech industry regarding mental health care or treatment.

#Family history and Treatment
The code below is to plot graphs to stduy the relationship or see if the fsmily history is strongly associated with the target variable 'treatment'
```{r}
# studying the family_history variable
f1 <- survey %>% ggplot(aes(x=family_history)) +
  geom_bar(fill = "pink")
f1
# Comparing Family_history treatment ratio
f2 <- survey %>% ggplot(aes(x=family_history, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Family_history Treatment Ratio for the entire data")
f2
# Comparing Family_history treatment ratio focusing on tech industy
f3 <- Tech %>% ggplot(aes(x=family_history, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Family_history Treatment Ratio for Tech field")
f3

```
It is evident from the graph that more than 60% of the population in the survey did not have a family history if mental health disorder. However, those who did seek mental health treatment do seem to have a family history.


# Treatment ratio in the tech industry

The code below is to plot graph to view the treatment ratio in each of the company sizes. 
```{r}
# level_order
level_order1 <- factor(Tech$no_employees, levels = c("1-5","6-25","26-100","100-500", "500-1000","More than 1000"))
#Treatment ratio in the  tech industry
z1 <- Tech %>% ggplot(aes(x=level_order1, fill = (treatment))) +
  geom_bar(position = "fill") + ggtitle("Treatment Ratio in the Tech Industry")
z1
```

The above graph bursts a myth that seeking mental health treatment does not do much with the size of the company. Generally the smaller the company or a startup, the more the stress. But this is proven to be wrong. Seeking mental health treatment is not depended on the size of the company. The above graph also shows that people belonging to companies from varied size have sought mental health treatment.
```{r,include=FALSE}
#Final dataframe with important variables focusing on answering the project goal
summary(Tech)
```

# MODELING

# LOGISTIC REGRESSION MODEL

Logistic regression model is mainly used for predicting discrete or categorical variables. One of the assumptions that this algorithm follows is that the target variable must be a binary variable.Moreover, logistic regression involves using a logistic function also known as sigmoid function that makes it possible to solve classification problems.We ran the logistic regression model using all the variables to cross verify our selection of the variables amongst the 27 available variables.

```{r}

# Fit logistic model to the data required to answer the project goal
lm <- glm( treatment ~ Age + Gender + no_employees + family_history, data = Tech, family = "binomial" )
summary(lm)
coef(lm)
```

We got the AIC value of 1258.2 which we will try to lower down or improve to make our model efficient. The significant variables are Gender Male and Family history_yes as they have the lowest p values and low error rate.This tells us that employees who are male, employees who have a family history of mental health care, and employees working in a company-sized between 500 to 1000 are more susceptible to having mental health issues.

We further split the data into training - 80% and test - 20% for the purpose of feature engineering.
```{r,message=FALSE}
#splitting the dataset to training and testing 
i <- nrow(Tech)
i
train_ind <- sample(seq_len(i), size = floor(0.8*i))

Tech_training <- Tech[train_ind, ]
Tech_testing <- Tech[-train_ind, ]
```
We define a transformation function for feature engineering.We apply the function to our training and testing data separately.
```{r,message=FALSE}
transformations <- function(Tech) {
  # Gender
  # Create the list of three categories
  Male <- c("Male ","Cis Man", "Malr", "Male", "male", "M", "m", "Male-ish", "maile", "Mal", "Male (CIS)", "Cis Male", "Make", "Male", "Man", "msle", "Mail", "cis male")
  Female <- c("Female ","femail","Female (cis)","female","Female","F","Woman","f","Femake","woman","Female","cis-female/femme", "Cis Female", "Trans-female", "Female (trans)", "Trans woman")
  Queer <-c ("ostensibly male, unsure what that really means","p","A little about you","queer","Neuter","something kinda male?","non-binary","Nah","All","Enby","fluid","Genderqueer","Androgyne","Agender","Guy (-ish) ^_^","male leaning androgynous", "queer/she/they")
  
  # Categorize genders
  Tech$Gender <- sapply(
    as.vector(Tech$Gender),
    function(x) if(x %in% Male) "Male" else x ) 
  
  Tech$Gender <- sapply(
    as.vector(Tech$Gender),
    function(x) if(x %in% Female) "Female" else x ) 
  
  Tech$Gender <- sapply(
    as.vector(Tech$Gender),
    function(x) if(x %in% Queer) "Queer" else x ) 
  
  # Age
  # Replacing negative values and outliers with median
  Tech$Age <- as.numeric(Tech$Age)
  Tech$Age[which(Tech$Age<0)]<- median(Tech$Age)
  Tech$Age[which(Tech$Age>100)]<- median(Tech$Age)
  
  # Summary Age
  summary(Tech$Age)
  
  # Age categorization#
  Tech$Age1 <- cut(Tech$Age, breaks = c(0, 16, 34, 60, 75), labels = c('Fresh', 'Junior', 'Senior', 'Super'))
  
  # Verify Age group
  Tech$Age1 %>% table
  
  # Return the transformed dataframe
  return(Tech)
}
# Feature Engineerung for Test and Train Dataset
Tech_training <- Tech_training %>% transformations
Tech_testing <- Tech_testing %>% transformations

# Train Data
Tech_training %>% head(2)

# Test data
Tech_testing %>% head(2)
```

We train the the logistic regression model using the training dataset to make predictions on the train and test data.
```{r}
# Training the logistic regression model  with feature engineering 
lm_train <- glm(treatment ~ Age + Gender + family_history + no_employees, data = Tech_training, family = "binomial")
summary(lm_train)
```
We see that logistic regression model with feature engineering improved the value of the AIC to 1007 from 1258.2. Thought the significant variables remain the same, we got a better performing model than the previous one.

The code below makes predictions on the training and the testing set and computes the confusion matrix and the accuracy.
```{r}
# Predictions on the training set
Tech_training$predict_probs <- predict(lm_train, Tech_training, type = "response")
Tech_training$predict <- ifelse(Tech_training$predict_probs < 0.5, "No", "Yes")
# Predictions on the test set
Tech_testing$predict_probs <- predict(lm_train, Tech_testing, type = "response")
Tech_testing$predict <- ifelse(Tech_testing$predict_probs < 0.5, "No", "Yes")
# Confusion matrix for training data 
cm_train <- table(Tech_training$treatment, Tech_training$predict, dnn = c("real", "predict"))
cm_train
paste('Accuracy:', round(( cm_train['Yes','Yes'] + cm_train['No','No'] ) / sum(cm_train),2))
# Confusion matrix for testing data
cm_test <- table(Tech_testing$treatment, Tech_testing$predict, dnn = c("real", "predict"))
cm_test
paste('Accuracy:', round(( cm_test['Yes','Yes'] + cm_test['No','No'] ) / sum(cm_test),2))
```
We achieved the accuracy of 70% with this model.That also means the model indicates that 73% of the mental health treatment predictions are correct and accurate. 

# OPTIMIZATION - LOGISTIC REGRESSION MODEL
In order to further improve the logistic regression model with feature engineering built above, we tried optimizing the model with stepwise AIC criterion. We chose stepwise AIC as it considers all the candidate variables in each step and checks if they fall below a certain threshold value. It works by eliminating the insignificant variables and thus reduces the complexity on the model leading to better performance.

library(MASS)
```{r}
#OPTIMIZATION
#STEP AIC
library(MASS)
step.model <- lm_train %>% stepAIC(trace = FALSE)
coef(step.model)
#Predictions
probabilities <- predict(step.model, Tech_testing, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "Yes", "No")
cm_1 <- table(Tech_testing$treatment, predicted.classes, dnn = c("real", "predict"))
cm_1
paste('Accuracy:', round(( cm_1['Yes','Yes'] + cm_1['No','No'] ) / sum(cm_1),2))
```
The results of the optimization model tells us that Gender Male and Queer along with family history are the most significant variables for us to predict if an employee in the tech company needs to seek a mental health treatment. Also the model yield an accuracy of 71% which is the same as the previous model.However, it gave us one more attribute 'Queer' which is significant for our prediction. It also reduced the complexity on the model by selecting the most significant ones.

# KNN MODEL

KNN is one of the most commonly used supervised machine learning algorithms. It can be used for classification, regression and forecasting. We used KNN as a classifier since our project goal was to identify who needs treatment. KNN works by considering K nearest data points for predicting a class, where the classes will be ‘yes’ or ‘no’ for treatment needed or not respectively. Euclidean distance is calculated between new data points and the nearest neighbors. This algorithm has many advantages like no assumptions are made (non-parametric) , intuitive and all data is used hence we chose to implement it . 
```{r}
# BUILDING THE KNN MODEL
trControl <- trainControl(method = 'repeatedcv',
                          number = 10,
                          repeats = 10)
set.seed(333)
fit <- train(treatment ~.,
             data = Tech_training,
             tuneGrid = expand.grid(k=2),
             method = 'knn',
             trControl = trControl)

predict_knn <- predict(fit,Tech_testing)
cm_knn <- with(Tech_testing,table(predict_knn,treatment))
cm_knn
paste('Accuracy:', sum(diag(cm_knn)) / sum(cm_knn) * 100 )
```
We got an accuracy of 66.66% for this model by setting a few parameters. We used repeated cross-validation, so the dataset is split randomly and divided into k folds of equal length and reiterate on all the folds. We set the value of k=2. By using trainControl() we repeated the steps for 10 times. There were 90 and 45 employees that were classified correctly by the model who did not need treatment and later who needed to treatment.There were 59(25 + 34) incorrect predictions made by this model.We got a better accuracy with KNN model.


# RANDOM FOREST MODEL

Random Forest can be defined as a model which can be defined as the model that combines together multiple decision trees of different depths in predicting the model. Here we have used random forest for improving our accuracy of the model as it reduces the overall complexity of the model that is being built. Random Forest helps in building the model that gives us information about the relationships between models and its classification.  The goal in building this model is to get good predictions on the unseen data.

```{r,include=FALSE}
library(randomForest)
library(scales)
```
```{r}
control <- trainControl(method="repeatedcv", number = 5)
grid <- data.frame(mtry = c(1, 5, 10))

train_rf <-  train(treatment ~., Tech_training, 
                   method = "rf", 
                   ntree = 500,
                   trControl = control,
                   tuneGrid = grid,
                   nSamp = 5000)

ggplot(train_rf)

predict <- predict(train_rf,Tech_testing)
cm <- with(Tech_testing,table(predict,treatment))
cm
paste('Accuracy:', sum(diag(cm)) / sum(cm) * 100 )
```
Here we used random forest with repeated cross-validation which helps us in error estimation in the problem and also introduces a bias in the data thereby strengthening its prediction on the unseen data. The ntree (number of decision trees) was set to 500 and parameter tuneGrid was set to grid . Whereas nSamp was set to 5000.The accuracy of the model predicted is 70.04%. Understanding the confusion matrix we can say as follows:

1. For 83 cases the model predicted no treatment and those cases actually were classified into no treatment category.(False Negative)
2. For 62 cases we predicted that they need treatment and truly they were classified into the treatment required category.(True Positive)
3. For 30 cases we predicted no treatment but they actually needed treatment.(False Positive)
4. Lastly in 32 cases again we predicted they needed treatment but didn't undergo treatment.(False Negative)

# XgBoost

XGboost is a decision tree based model which is known to improve speed and performance. This model can also be used as a regressor and classifier. It is an ensemble model since it creates new models based on errors of the previous one to improve performance. This process is carried on until no changes or improvements can be made. As the name says gradient boosting it uses gradient descent to reduce the cost and reach to convergence point ( optimal value/point).  When the learning rate is set to a low value it will take a lot of time to reach the optimal point and if it is set to a large value then it may never reach the optimal value .For learning rate the value can range from 0 to 1 which is also known as shrinkage(eta) . Parameter  max_depth controls the depth of the tree also it was observed that as the length of the tree increases and the complexity of the model increases leading to overfitting of the model. The gamma parameter is responsible for regularization and preventing overfitting.

```{r}
parameterGrid <-  expand.grid(eta = 0.1, # shrinkage (learning rate)
                              colsample_bytree = c(0.5,0.7), # subsample ration of columns
                              max_depth = c(5,7), # max tree depth. model complexity
                              nrounds = 10, # boosting iterations
                              gamma = 1, # minimum loss reduction
                              subsample = 0.8, # ratio of the training instances
                              min_child_weight = 1) # minimum sum of instance weight

model_xgb <- train(treatment ~ .,
                   data = Tech_training,
                   method = "xgbTree",
                   trControl = trainControl(),
                   tuneGrid=parameterGrid)
model_xgb

predict1 <- predict(model_xgb,Tech_testing)
cm1 <- with(Tech_testing,table(predict1,treatment))
cm1
paste('Accuracy:', sum(diag(cm1)) / sum(cm1) * 100 )
```
Using this model we achieved an accuracy of 71%. Multiple parameters are used to tune the XGBoost model like learning rate , gamma , sub-sample ratio.A learning rate of 0.1 was selected to reach optimal value and reduce the overfitting of the data .The parameter nrounds was set as 10 .Subsample ratio was set as 0.8 to randomly select 80% of training data. The sum of weights for child nodes was considered as 1. A combination of tuning parameters were tried for better performance.Out of 148 employees which were correctly classified , 52 employees were predicted to undergo treatment and 96 as treatment not needed. Whereas 59 employees were misclassified. 


# SUPPORT VECTOR MACHINE MODEL

Support vector machines (SVM) can be used as a regressor as well as classifier.  For our project we used SVM as a classifier since we needed to predict whether a person needs treatment or not.Support Vector Machine works by creating a margin between classes and a maximum marginal boundary is selected to separate classes from each other.  Here the concept of support vector ( data points ) is used for maximizing the margin . Support vectors are responsible for positioning the hyperplane margins . One of the advantages of using this algorithm is that it uses less memory because of subsetting training data .There are various kernel options available to model the data linear , polynomial and radial basis function .
```{r}
library(e1071) 
model_svm<-svm(treatment~.,data=Tech_training,kernel='linear',gamma= 1,cost=100)
model_svm
test_pred <- predict(model_svm, newdata = Tech_testing)
test_pred
confusionMatrix(test_pred, Tech_testing$treatment )
```


We got accuracy of 73.43% using this model. There were few parameters that we tuned while building the model like cost which was set to 100.We used the kernel as ‘linear’ because classification of only two classes had to be done. If training data is increased the accuracy increases as well as kappa value is better. 

# Conclusion
SVM, random forest and logistic regression model with feature engineering gave the best performance
amongst all the models that we ran in our dataset. Highest accuracy was observed for this model that
means it correctly classified most of the data as treatment needed ‘yes’ as ‘yes’ and treatment not needed to
be ‘no’ as ‘no’ . Moreover, the logistic model helped us identify significant attributes that the tech industry
should have focused on so that they can help the employees who are in dire need of treatment.
Furthermore,based on the results we can say that gender and family history plays an important role in the determination of seeking mental health care. The number of men in the tech industry is relatively higher than the number of females, which may create gender baisity in the work environment leading to stress. Family history also plays a major role in mental health as a sound mind helps in giving a better performance in the workplace. When considered managing both family and work simultaneously which can be burdened and disturb the work-life balance leading to more susceptible to having mental health problems.
It can be summarized that tech companies should have schemes so that people can seek mental health care. Gender is one of the prominent variables determining mental health care so, companies can try maniniting the gender ratio. Companies should focus on employees and their mental health problems and should have a seperate care mental health department or a counselor to address their issues.
For further analysis we should have a detailed survey which includes the number of hours worked weekly, the stress level of each employee, workload etc., needs to be considered and also the attributes other than feature variables that are affecting mental health needs to be taken into consideration for more clarity and better precise prediction and arrive at a more prominent conclusion.   







